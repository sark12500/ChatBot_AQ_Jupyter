{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 閒聊準備工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# import sys\n",
    "# import os\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import pandas as pd\n",
    "\n",
    "class JiebaSegmentor:\n",
    "\n",
    "    def __init__(self, dict_path, userdict = []):\n",
    "        self.__dict_path = dict_path\n",
    "        self.__userdict = userdict\n",
    "        self.dictionary_init()\n",
    "    \n",
    "    def dictionary_init(self):\n",
    "        jieba.set_dictionary(self.__dict_path)\n",
    "        for path in self.__userdict:\n",
    "            jieba.load_userdict(path)\n",
    "    \n",
    "    def get_names(self, input_text):\n",
    "        names=[]\n",
    "        words = pseg.cut(input_text)\n",
    "        print words\n",
    "        for w,f in words:\n",
    "            if f.lower() == 'nr':\n",
    "                names.append(w)\n",
    "        for name in names:\n",
    "            print name.encode('utf-8')\n",
    "        return names\n",
    "            \n",
    "    def lcut(self, input_text):\n",
    "        cut_raw = jieba.lcut(input_text)\n",
    "        return cut_raw\n",
    "    \n",
    "    def pseg_lcut(self, input_text):\n",
    "        cut_raw = pseg.lcut(input_text)\n",
    "        key = []\n",
    "        value = []\n",
    "        \n",
    "        for k,v in cut_raw:\n",
    "            key.append(k)\n",
    "            value.append(v)\n",
    "        df = pd.DataFrame({\"word\":key, \"tag\":value})\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "Loading model cost 0.239 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.239 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>請問</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>今天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v</td>\n",
       "      <td>下雨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>嗎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>請問</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t</td>\n",
       "      <td>今天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v</td>\n",
       "      <td>下雨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x</td>\n",
       "      <td>嗎</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag word\n",
       "0   x   請問\n",
       "1   t   今天\n",
       "2   v   下雨\n",
       "3   x    嗎\n",
       "4   x   請問\n",
       "5   t   今天\n",
       "6   v   下雨\n",
       "7   x    嗎"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba_dict_path = \"/home/charles/dataset/userdict.txt\"\n",
    "segmentor = JiebaSegmentor(jieba_dict_path)\n",
    "df = segmentor.pseg_lcut('請問今天下雨嗎請問今天下雨嗎')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import *\n",
    "from gensim.models import TfidfModel\n",
    "from datetime import datetime\n",
    "from gensim import models\n",
    "\n",
    "class TfidfGensim:\n",
    "\n",
    "    def __init__(self, model_path, dictionary_path, stopword_path,\n",
    "                 jieba_dict_path, jieba_user_dict_path_list=[]):\n",
    "        self.__model_path = model_path\n",
    "        self.model = None\n",
    "        self.model_init()\n",
    "        self.__stopword_path = stopword_path\n",
    "        self.stopword_set = set()\n",
    "        self.stopword_init()\n",
    "        self.__dictionary_path = dictionary_path\n",
    "        self.dictionary_init()\n",
    "        self.jieba_dict_path = jieba_dict_path\n",
    "        self.jieba_user_dict_path_list = jieba_user_dict_path_list\n",
    "        self.segmentor = None\n",
    "        self.jieba_init()\n",
    "\n",
    "    def stopword_init(self):\n",
    "        self.stopword_set = set()\n",
    "        with open(self.__stopword_path,'r') as stopwords:\n",
    "            for sw in stopwords:\n",
    "                self.stopword_set.add(sw.strip('\\n').decode('utf-8'))\n",
    "    \n",
    "    def model_init(self):\n",
    "        self.model = TfidfModel.load(self.__model_path)\n",
    "\n",
    "    def dictionary_init(self):\n",
    "        self.dictionary = Dictionary.load(self.__dictionary_path)\n",
    "    \n",
    "    def jieba_init(self):\n",
    "        self.segmentor = JiebaSegmentor(self.jieba_dict_path, self.jieba_user_dict_path_list)\n",
    "\n",
    "    def predict(self, input_text):\n",
    "        words = segmentor.pseg_lcut(input_text)\n",
    "        subject_dict={}\n",
    "        for index, row in words.iterrows():\n",
    "#             print row['word'] + ' (' + row['tag'] + ')'\n",
    "            subject_dict.update({row['word']:row['tag']})\n",
    "            \n",
    "        corpus = []\n",
    "        for index, row in words.iterrows():\n",
    "            if row['word'] not in self.stopword_set:\n",
    "                corpus.append(row['word'])\n",
    "            \n",
    "        corpus_key = self.dictionary.doc2bow(corpus)\n",
    "        corpus_tfidf = self.model[corpus_key]\n",
    "        corpus_tfidf = sorted(corpus_tfidf, key=lambda item: item[1], reverse=True)\n",
    "        id2token = dict(zip(self.dictionary.token2id.values(), self.dictionary.token2id.keys()))\n",
    "#         result = []\n",
    "        key = []\n",
    "        value = []\n",
    "        for i in range(len(corpus_tfidf)):\n",
    "#             result.update({id2token[corpus_tfidf[i][0]]: corpus_tfidf[i][1]})\n",
    "#             print \"--------------------------------------\"\n",
    "            word = id2token[corpus_tfidf[i][0]]\n",
    "            tfidf = corpus_tfidf[i][1]\n",
    "#             print 'keyword: ' + word + '(' + subject_dict[word] + ') , tfidf: ' + str(tfidf)\n",
    "            key.append(word)\n",
    "            value.append(tfidf)\n",
    "#             result.append((word, tfidf))\n",
    "        \n",
    "        df = pd.DataFrame({\"word\":key, \"tfidf\":value})\n",
    "        return df\n",
    "\n",
    "#         return result\n",
    "#             try:\n",
    "#                 w2v_predict(w2v_model, word)\n",
    "#             except KeyError as er:\n",
    "#                 print 'no synonyms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "Loading model cost 0.246 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.246 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請問 (x)\n",
      "今天 (t)\n",
      "下雨 (v)\n",
      "嗎 (x)\n",
      "--------------------------------------\n",
      "keyword: 請問(x) , tfidf: 0.8771051416986487\n",
      "--------------------------------------\n",
      "keyword: 今天(t) , tfidf: 0.3464878958700677\n",
      "--------------------------------------\n",
      "keyword: 下雨(v) , tfidf: 0.33261495519793777\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_path = \"/home/charles/dataset/tfidf_model/tfidf.model\"\n",
    "tfidf_dictionary_path = \"/home/charles/dataset/model/tfidf_corpus_dict\"\n",
    "stopwords_path = \"/home/charles/dataset/stopwords.txt\"\n",
    "jieba_dict_path = \"/home/charles/dataset/userdict.txt\"\n",
    "\n",
    "tg = TfidfGensim(tfidf_model_path, tfidf_dictionary_path, \n",
    "                   stopwords_path, \n",
    "                   jieba_dict_path)\n",
    "tg.predict('請問今天下雨嗎')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "class WordToVecGensim:\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.__model_path = model_path\n",
    "        self.model_init()\n",
    "\n",
    "    def model_init(self):\n",
    "        self.model = models.Word2Vec.load(self.__model_path)\n",
    "\n",
    "    def predict(self, input_text):\n",
    "\n",
    "        if type(input_text) is str:\n",
    "            input_text = input_text.decode('utf-8')\n",
    "\n",
    "        print 'synonyms : '\n",
    "        key = []\n",
    "        value = []\n",
    "        try:\n",
    "            res = self.model.wv.most_similar(input_text)\n",
    "            for item in res:\n",
    "                key.append(item[0])\n",
    "                value.append(item[1])\n",
    "#             result.append((word, tfidf))\n",
    "\n",
    "        except KeyError as er:\n",
    "            print 'no synonyms'\n",
    "\n",
    "        df = pd.DataFrame({\"word\":key, \"cof\":value})\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_path = \"/home/charles/dataset/word2vec_taiwan.model\"\n",
    "del w2v\n",
    "w2v = WordToVecGensim(w2v_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text: 關雲長\n",
      "synonyms : \n",
      "張豐毅: 0.746361374855\n",
      "湯鎮業: 0.737364172935\n",
      "銅雀臺: 0.735068023205\n",
      "薛剛: 0.731519162655\n",
      "劉家輝: 0.728982448578\n"
     ]
    }
   ],
   "source": [
    "input_text = '關雲長'\n",
    "print 'input_text: ' + input_text\n",
    "res = w2v.predict(input_text)\n",
    "res = list(res)\n",
    "for index,item in enumerate(res):\n",
    "    if index == 5:\n",
    "        break\n",
    "\n",
    "    if item[1] < 0.15:\n",
    "        break\n",
    "    print item[0] + ': ' + str(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問句分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 閒聊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba_dict_path = \"/home/charles/dataset/userdict.txt\"\n",
    "del segmentor\n",
    "segmentor = JiebaSegmentor(jieba_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model_path = \"/home/charles/dataset/tfidf_model/tfidf.model\"\n",
    "tfidf_dictionary_path = \"/home/charles/dataset/model/tfidf_corpus_dict\"\n",
    "stopwords_path = \"/home/charles/dataset/stopwords.txt\"\n",
    "jieba_dict_path = \"/home/charles/dataset/userdict.txt\"\n",
    "\n",
    "del tg\n",
    "tg = TfidfGensim(tfidf_model_path, tfidf_dictionary_path, \n",
    "                   stopwords_path, \n",
    "                   jieba_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_path = \"/home/charles/dataset/word2vec_taiwan.model\"\n",
    "del w2v\n",
    "w2v = WordToVecGensim(w2v_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>今天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>天氣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>好</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>晴朗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>路邊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>野花</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ns</td>\n",
       "      <td>香</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag word\n",
       "0   t   今天\n",
       "1   x   天氣\n",
       "2   a    好\n",
       "3   a   晴朗\n",
       "4   x    ,\n",
       "5   s   路邊\n",
       "6   n   野花\n",
       "7  ns    香"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = '今天天氣好晴朗,路邊野花香'\n",
    "df = segmentor.pseg_lcut(ww)\n",
    "df\n",
    "# for index, row in df.iterrows():\n",
    "#     print row['word']+ '(' + row['tag']+ ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from /home/charles/dataset/userdict.txt ...\n",
      "Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.ubc05a47a38c222127669bf922eb0875d.cache\n",
      "Loading model cost 0.255 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.255 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.915588</td>\n",
       "      <td>晴朗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303557</td>\n",
       "      <td>天氣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152305</td>\n",
       "      <td>野花</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143543</td>\n",
       "      <td>今天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121165</td>\n",
       "      <td>路邊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.076593</td>\n",
       "      <td>香</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.072126</td>\n",
       "      <td>好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tfidf word\n",
       "0  0.915588   晴朗\n",
       "1  0.303557   天氣\n",
       "2  0.152305   野花\n",
       "3  0.143543   今天\n",
       "4  0.121165   路邊\n",
       "5  0.076593    香\n",
       "6  0.072126    好"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = '今天天氣好晴朗,今天天氣好晴朗,路邊野花香,晴朗,晴朗,晴朗'\n",
    "df = tg.predict(ww)\n",
    "df\n",
    "# for item in res:\n",
    "#     print item[0] + '(' + str(item[1]) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cof</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701232</td>\n",
       "      <td>今日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.652387</td>\n",
       "      <td>如今</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.648781</td>\n",
       "      <td>現在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.531828</td>\n",
       "      <td>那時</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514310</td>\n",
       "      <td>現今</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.512732</td>\n",
       "      <td>昨天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.485135</td>\n",
       "      <td>當今</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.480213</td>\n",
       "      <td>原來</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.469453</td>\n",
       "      <td>這裡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.460246</td>\n",
       "      <td>這兒</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cof word\n",
       "0  0.701232   今日\n",
       "1  0.652387   如今\n",
       "2  0.648781   現在\n",
       "3  0.531828   那時\n",
       "4  0.514310   現今\n",
       "5  0.512732   昨天\n",
       "6  0.485135   當今\n",
       "7  0.480213   原來\n",
       "8  0.469453   這裡\n",
       "9  0.460246   這兒"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = w2v.predict('今天')\n",
    "df\n",
    "# for item in res:\n",
    "#     print item[0] + '(' + str(item[1]) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text):\n",
    "    # 斷詞\n",
    "    cut_text = segmentor.pseg_lcut(input_text)\n",
    "    # 問句分類\n",
    "    # 找關鍵字\n",
    "    keyword = tg.predict(input_text)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
