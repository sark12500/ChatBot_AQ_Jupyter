{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.policies import DCAwareRoundRobinPolicy\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.query import BatchStatement\n",
    "import pandas as pd\n",
    "\n",
    "class CassandraType(object):\n",
    "    PRODUCTION = 0\n",
    "    TEST = 1\n",
    "    TEST_DOCKER = 2\n",
    "\n",
    "\n",
    "class CassandraDAO(object):\n",
    "\n",
    "    # you have to install following items :\n",
    "    # a. python-Cassandra driver\n",
    "    # b. pyspark cassandra connector\n",
    "\n",
    "    def __init__(self, type):\n",
    "        print('init CassandraDAO')\n",
    "        if type == CassandraType.PRODUCTION:\n",
    "            self.contact_points = ['192.168.95.127', '192.168.95.122']\n",
    "            self.contact_points_str = \"192.168.95.127,192.168.95.122\"\n",
    "        elif type == CassandraType.TEST:\n",
    "            self.contact_points = ['192.168.0.41', '192.168.0.42']\n",
    "            self.contact_points_str = \"192.168.0.41,192.168.0.42\"\n",
    "        else:\n",
    "            self.contact_points = ['192.168.0.121', '192.168.0.122', '192.168.0.52']\n",
    "            self.contact_points_str = \"192.168.0.121,192.168.0.122,192.168.0.52\"\n",
    "\n",
    "        self.formatString = \"org.apache.spark.sql.cassandra\"\n",
    "        self.username = \"username\"\n",
    "        self.password = \"password\"\n",
    "        self.cluster = None\n",
    "        self.session = None\n",
    "        self.createSession()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cluster.shutdown()\n",
    "\n",
    "    def pandas_factory(self, colnames, rows):\n",
    "        return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "    def createSession(self):\n",
    "        print (\"contact_points = \" + self.contact_points_str)\n",
    "        self.cluster = Cluster(\n",
    "            contact_points=self.contact_points,  # random select a node\n",
    "            #             load_balancing_policy = DCAwareRoundRobinPolicy(local_dc='datacenter1'),\n",
    "            #         auth_provider = PlainTextAuthProvider(username='cassandra', password='cassandra')\n",
    "        )\n",
    "        self.session = self.cluster.connect()\n",
    "        self.session.row_factory = self.pandas_factory\n",
    "        self.session.default_fetch_size = 10000000\n",
    "        # needed for large queries, otherwise driver will do pagination. Default is 50000.\n",
    "\n",
    "    def getSession(self):\n",
    "        return self.session\n",
    "\n",
    "    def execCQL(self, keyspace, cql):\n",
    "        \"\"\"\n",
    "        execute CQL\n",
    "        \"\"\"\n",
    "        self.session.set_keyspace(keyspace)\n",
    "        self.session.execute_async(cql)\n",
    "\n",
    "    def execCQLSelect(self, keyspace, cql):\n",
    "        \"\"\"\n",
    "        execute CQL, select only\n",
    "        \"\"\"\n",
    "\n",
    "        self.session.set_keyspace(keyspace)\n",
    "\n",
    "        #       cassandra ResultSet\n",
    "        async_results = self.session.execute_async(cql)\n",
    "        return async_results\n",
    "\n",
    "    def execCQLCallBackAnysc(self, keyspace, cql, handle_success, handle_error):\n",
    "        \"\"\"\n",
    "        execute CQL, if success => handle_success function, else handle_error\n",
    "        \"\"\"\n",
    "        self.session.set_keyspace(keyspace)\n",
    "        async_results = self.session.execute_async(cql)\n",
    "        async_results.add_callbacks(handle_success, handle_error)\n",
    "\n",
    "    def execCQLSelectToPandasDF(self, keyspace, cql):\n",
    "        \"\"\"\n",
    "        execute CQL, select only, return Pandas DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        self.session.set_keyspace(keyspace)\n",
    "\n",
    "        #       cassandra ResultSet\n",
    "        async_results = self.session.execute_async(cql)\n",
    "        #         async_results = self.session.execute_async(cql)\n",
    "        #       to Pandas DataFrame\n",
    "        return async_results.result()._current_rows\n",
    "\n",
    "    def execCQLSelectToDF(self, sqlContext, keyspace, cql):\n",
    "        \"\"\"\n",
    "        execute CQL, select only, return Spark DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        #       pandas dataframe to spark dataframe\n",
    "        pandas_dataframe = self.execCQLSelectToPandasDF(keyspace, cql)\n",
    "        if pandas_dataframe.empty:\n",
    "            schema = StructType([])\n",
    "            return sqlContext.createDataFrame([], schema)\n",
    "        else:\n",
    "            return sqlContext.createDataFrame(pandas_dataframe)\n",
    "\n",
    "    def execCQLSelectToRDD(self, sqlContext, keyspace, cql):\n",
    "        \"\"\"\n",
    "        execute CQL, select only, return Spark RDD\n",
    "        \"\"\"\n",
    "\n",
    "        return self.execCQLSelectToDF(sqlContext, keyspace, cql).rdd.map(tuple)  # dataFrame to RDD\n",
    "\n",
    "    @property\n",
    "    def contactPoints(self):\n",
    "        return self.contact_points\n",
    "\n",
    "    @contactPoints.setter\n",
    "    def contactPoints(self, contact_points):\n",
    "        self.contact_points = contact_points\n",
    "\n",
    "    @contactPoints.deleter\n",
    "    def contactPoints(self):\n",
    "        del self.contact_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init CassandraDAO\n",
      "contact_points = 192.168.95.127,192.168.95.122\n"
     ]
    }
   ],
   "source": [
    "CASSANDRA_ENV = CassandraType.PRODUCTION\n",
    "c_dao = CassandraDAO(CASSANDRA_ENV)\n",
    "HELPER_TEST_KEYSPACE='helper_test_keyspace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import decimal\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "# import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "\n",
    "class JiebaSegmentor:\n",
    "\n",
    "    def __init__(self, dict_path, userdict=[], stopwords=False, stopwords_path=None):\n",
    "        self.dict_path = dict_path\n",
    "        self.userdict = userdict\n",
    "        self.dictionary_init()\n",
    "        self.stopwords_path = stopwords_path\n",
    "        self.stopwords = stopwords\n",
    "        self.stopwords_set = set()\n",
    "        self.stopwords_init()\n",
    "\n",
    "    def dictionary_init(self):\n",
    "        jieba.set_dictionary(self.dict_path)\n",
    "        for path in self.userdict:\n",
    "            print path\n",
    "            jieba.load_userdict(path)\n",
    "\n",
    "    def stopwords_init(self):\n",
    "        if self.stopwords_path:\n",
    "            with open(self.stopwords_path, 'r') as stopwords:\n",
    "                for stopword in stopwords:\n",
    "                    self.stopwords_set.add(stopword.strip('\\n').decode('utf-8'))\n",
    "\n",
    "    def taiwan_country(self):\n",
    "        return [u'臺北', u'台北', u'基隆', u'臺中', u'台中', u'臺南', u'台南', u'高雄',\n",
    "                u'宜蘭', u'桃園', u'新竹', u'苗栗', u'彰化', u'南投', u'嘉義', u'雲林',\n",
    "                u'屏東', u'臺東', u'台東', u'花蓮', u'澎湖']\n",
    "\n",
    "    def wordToNumber(self, input_text):\n",
    "\n",
    "        target = u''\n",
    "        for s in input_text:\n",
    "\n",
    "            if (s == u'零') or (s == '0'):\n",
    "                to_word = u'0'\n",
    "            elif (s == u'一') or (s == u'壹') or (s == '1'):\n",
    "                to_word = u'1'\n",
    "            elif (s == u'二') or (s == u'兩') or (s == u'貳') or (s == '2'):\n",
    "                to_word = u'2'\n",
    "            elif (s == u'三') or (s == u'參') or (s == '3'):\n",
    "                to_word = u'3'\n",
    "            elif (s == u'四') or (s == u'肆') or (s == '4'):\n",
    "                to_word = u'4'\n",
    "            elif (s == u'五') or (s == u'伍') or (s == '5'):\n",
    "                to_word = u'5'\n",
    "            elif (s == u'六') or (s == u'陸') or (s == '6'):\n",
    "                to_word = u'6'\n",
    "            elif (s == u'七') or (s == u'柒') or (s == '7'):\n",
    "                to_word = u'7'\n",
    "            elif (s == u'八') or (s == u'捌') or (s == '8'):\n",
    "                to_word = u'8'\n",
    "            elif (s == u'九') or (s == u'玖') or (s == '9'):\n",
    "                to_word = u'9'\n",
    "            else:\n",
    "                to_word = s\n",
    "\n",
    "        target = target + to_word\n",
    "        return target\n",
    "\n",
    "    def input_text_preprocessing(self, input_text):\n",
    "\n",
    "        if type(input_text) is not unicode:\n",
    "            input_text = input_text.decode('utf-8')\n",
    "\n",
    "        #         input_text = self.wordToNumber(input_text)\n",
    "        return input_text\n",
    "\n",
    "    def get_names(self, input_text):\n",
    "        \"\"\"\n",
    "        取得姓名\n",
    "        :param input_text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        input_text = self.input_text_preprocessing(input_text)\n",
    "        names = []\n",
    "        words = pseg.cut(input_text)\n",
    "        print words\n",
    "        for w, f in words:\n",
    "            if f.lower() == 'nr':\n",
    "                names.append(w)\n",
    "        for name in names:\n",
    "            print name.encode('utf-8')\n",
    "        return names\n",
    "\n",
    "    def lcut(self, input_text, return_type='pandas'):\n",
    "        \"\"\"\n",
    "        斷詞\n",
    "        :param input_text:\n",
    "        :param return_type:\n",
    "        :return: pandas\n",
    "        \"\"\"\n",
    "\n",
    "        input_text = self.input_text_preprocessing(input_text)\n",
    "        cut_raw = jieba.lcut(input_text)\n",
    "        key = []\n",
    "\n",
    "        for k in cut_raw:\n",
    "            if self.stopwords:\n",
    "                if k in self.stopwords_set:\n",
    "                    continue\n",
    "\n",
    "            key.append(k)\n",
    "\n",
    "        result = pd.DataFrame({\"word\": key})\n",
    "        if return_type == 'pandas':\n",
    "            return result\n",
    "        elif return_type == 'dict':\n",
    "            return result.to_dict('index').values()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def pseg_lcut(self, input_text, return_type='pandas'):\n",
    "        \"\"\"\n",
    "        斷詞+詞性\n",
    "        :param input_text:\n",
    "        :param return_type:\n",
    "        :return: pandas\n",
    "        \"\"\"\n",
    "\n",
    "        input_text = self.input_text_preprocessing(input_text)\n",
    "        cut_raw = pseg.lcut(input_text)\n",
    "        key = []\n",
    "        value = []\n",
    "\n",
    "        for k, v in cut_raw:\n",
    "            tag = v\n",
    "            if self.stopwords:\n",
    "                if k in self.stopwords_set:\n",
    "                    continue\n",
    "\n",
    "            if k in self.taiwan_country():\n",
    "                tag = u'ns'\n",
    "            if len(k) > 1 and tag == u'x':\n",
    "                tag = u'n'\n",
    "            key.append(k)\n",
    "            value.append(tag)\n",
    "\n",
    "        result = pd.DataFrame({\"word\": key, \"tag\": value})\n",
    "        if return_type == 'pandas':\n",
    "            return result\n",
    "        elif return_type == 'dict':\n",
    "            return result.to_dict('index').values()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def pseg_lcut_combie_num_eng(self, input_text, return_type='pandas'):\n",
    "        \"\"\"\n",
    "        將數字與英文結合成同一欄位\n",
    "        :param input_text:\n",
    "        :param return_type:\n",
    "        :return: pandas\n",
    "        \"\"\"\n",
    "\n",
    "        input_text = self.input_text_preprocessing(input_text)\n",
    "        seg_pd = self.pseg_lcut(input_text)\n",
    "        seg_dict_list = []\n",
    "        m_eng_list = []\n",
    "        CombieTuple = namedtuple('CombieTuple', {\n",
    "            'index',\n",
    "            'word',\n",
    "            'sp'})\n",
    "\n",
    "        for index, seg in seg_pd.iterrows():\n",
    "            #     print type(seg)\n",
    "            #     print seg\n",
    "            seg_dict = {\n",
    "                \"word\": seg['word'],\n",
    "                \"sp\": seg['tag']\n",
    "            }\n",
    "\n",
    "            if seg['tag'] == 'm':\n",
    "                #         m_eng_dict.update(seg_dict)\n",
    "                combie_tuple = CombieTuple(\n",
    "                    index=index,\n",
    "                    word=seg['word'],\n",
    "                    sp=seg['tag']\n",
    "                )\n",
    "                m_eng_list.append(combie_tuple)\n",
    "            #             continue\n",
    "\n",
    "            if seg['tag'] == 'eng':\n",
    "                if m_eng_list:\n",
    "                    if m_eng_list[0].index + 1 == index:\n",
    "                        seg_dict = {\n",
    "                            \"word\": m_eng_list[0].word + seg['word'],\n",
    "                            \"sp\": m_eng_list[0].sp + '+' + seg['tag']\n",
    "                        }\n",
    "                        m_eng_list = []\n",
    "                        del seg_dict_list[index - 1]\n",
    "\n",
    "            seg_dict_list.append(seg_dict)\n",
    "\n",
    "        if return_type == 'pandas':\n",
    "            return pd.DataFrame(seg_dict_list)\n",
    "        elif return_type == 'dict':\n",
    "            return seg_dict_list\n",
    "        else:\n",
    "            return pd.DataFrame(seg_dict_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba_data_set = 'dataset_01'\n",
    "jieba_dict_path1 = \"/home/charles/dataset/jieba/\" + jieba_data_set +  \"/dict_taiwan.txt\"\n",
    "jieba_dict_path2 = \"/home/charles/dataset/jieba/\" + jieba_data_set +  \"/userdict.txt\"\n",
    "jieba_dict_path3 = \"/home/charles/dataset/jieba/\" + jieba_data_set +  \"/dict.txt.big\"\n",
    "jieba_dict_path4 = \"/home/charles/dataset/jieba/\" + jieba_data_set +  \"/dict.txt.small\"\n",
    "jieba_stopwords_path = \"/home/charles/dataset/jieba/\" + jieba_data_set +  \"/stopwords.txt\"\n",
    "\n",
    "js = JiebaSegmentor(dict_path=jieba_dict_path1,\n",
    "                    userdict=[],\n",
    "                    stopwords=True,\n",
    "                    stopwords_path=jieba_stopwords_path)\n",
    "# js = JiebaSegmentor(jieba_dict_path1, [jieba_dict_path2, jieba_dict_path3, jieba_dict_path4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/charles/dataset/jieba/dataset_01/dict_taiwan.txt ...\n",
      "DEBUG:jieba:Building prefix dict from /home/charles/dataset/jieba/dataset_01/dict_taiwan.txt ...\n",
      "Loading model from cache /tmp/jieba.uabe385690ac6efabcf7cebe5190ee7b2.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.uabe385690ac6efabcf7cebe5190ee7b2.cache\n",
      "Loading model cost 0.311 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.311 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word\n",
       "0   北京"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cut_raw_0 = js.lcut('北京在哪呢', return_type='df')\n",
    "test_cut_raw_0\n",
    "# for x in test_cut_raw_0:\n",
    "#     print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = ['air', 'coffee', 'leave', 'po', 'point', 'qcall', 'traffic', 'weather']\n",
    "\n",
    "def to_cat_name(x): \n",
    "    mapping_name_list = []\n",
    "    for item in x:\n",
    "        mapping_name_list.append(mapping_list[int(item)])\n",
    "    return mapping_name_list\n",
    "\n",
    "def cut_to_word(s):\n",
    "    w_df = js.lcut(s, return_type='pandas')\n",
    "    combie = ''\n",
    "    for i,w in w_df.iterrows():\n",
    "        combie = combie + w\n",
    "        if i < len(w_df) - 1:\n",
    "            combie = combie + ','\n",
    "            \n",
    "#     w_list = js.lcut(s, cut_type='list')\n",
    "#     combie = ''\n",
    "#     for i,w in enumerate(w_list):\n",
    "#         combie = combie + w\n",
    "#         if i < len(w_list) - 1:\n",
    "#             combie = combie + ','\n",
    "            \n",
    "    return combie\n",
    "\n",
    "def predict_class(model, data):\n",
    "\n",
    "    y_predict_probability = model.predict(data, batch_size=64, verbose=1)\n",
    "    predict_arr = []\n",
    "    predictClass = []\n",
    "    for row in y_predict_probability: \n",
    "            classIndex=0\n",
    "            selectClass=0\n",
    "            selectProbability=0\n",
    "            for item in row: \n",
    "                #print(float(item))\n",
    "                if(selectProbability <= float(item)):\n",
    "                    #print(classIndex)\n",
    "                    selectProbability=float(item)\n",
    "                    selectClass=classIndex\n",
    "                classIndex=classIndex+1\n",
    "            predictClass.append(selectClass)\n",
    "             \n",
    "    return to_cat_name(predictClass), predictClass, y_predict_probability\n",
    "\n",
    "def float_to_str(f, float_display):\n",
    "\n",
    "    return round(f, float_display)\n",
    "\n",
    "# # create a new context for this task\n",
    "# ctx = decimal.Context()\n",
    "# # 20 digits should be enough for everyone :D\n",
    "# float_display = 4\n",
    "# ctx.prec = float_display\n",
    "# def float_to_str(f):\n",
    "#     \"\"\"\n",
    "#      Convert the given float to a string,\n",
    "#      without resorting to scientific notation\n",
    "#     \"\"\"\n",
    "\n",
    "#     return round(f, float_display)\n",
    "#     d1 = ctx.create_decimal(repr(f))\n",
    "#     return format(d1, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_intent'\n",
    "# model_path = 'model/{}.h5'.format(model_name)\n",
    "model_path = '/home/charles/dataset/model/intent/{}.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "# loading model > tokenizer\n",
    "# tokenizer_path = 'model/tokenizer_intent.pickle'\n",
    "tokenizer_path = '/home/charles/dataset/model/intent/tokenizer_intent.pickle'\n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer_intent = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = ['明天班機有正常起飛嗎','現在國道北上塞車嗎']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>明天班機有正常起飛嗎</td>\n",
       "      <td>明天,班機,正常,起飛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>現在國道北上塞車嗎</td>\n",
       "      <td>現在,國道,北上,塞車</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence    cut_words\n",
       "0  明天班機有正常起飛嗎  明天,班機,正常,起飛\n",
       "1   現在國道北上塞車嗎  現在,國道,北上,塞車"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_df = pd.DataFrame({'sentence':input_text})\n",
    "input_text_df['cut_words'] = input_text_df['sentence'].apply(lambda s: cut_to_word(s.strip()))\n",
    "input_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(cut_words, max_len=10):\n",
    "    \n",
    "    #將文字轉為數字序列\n",
    "    train_seq_intent = tokenizer_intent.texts_to_sequences(cut_words)\n",
    "#     print train_seq_intent\n",
    "\n",
    "    # 截長補短，讓所有影評所產生的數字序列長度一樣\n",
    "    seq = sequence.pad_sequences(train_seq_intent, maxlen=max_len)\n",
    "#     print data.shape\n",
    "    return seq\n",
    "\n",
    "cut_words = input_text_df.cut_words\n",
    "seq = preprocessing(cut_words, max_len=10)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2/2 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_sentence</th>\n",
       "      <th>2_y_predict</th>\n",
       "      <th>3_y_predict_name</th>\n",
       "      <th>4_y_predict_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>明天班機有正常起飛嗎</td>\n",
       "      <td>2</td>\n",
       "      <td>leave</td>\n",
       "      <td>[0.1522, 0.3515, 0.4963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>現在國道北上塞車嗎</td>\n",
       "      <td>2</td>\n",
       "      <td>leave</td>\n",
       "      <td>[0.1522, 0.3515, 0.4963]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_sentence  2_y_predict 3_y_predict_name   4_y_predict_probability\n",
       "0  明天班機有正常起飛嗎            2            leave  [0.1522, 0.3515, 0.4963]\n",
       "1   現在國道北上塞車嗎            2            leave  [0.1522, 0.3515, 0.4963]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_name, y_predict, y_predict_probability = predict_class(model, seq)\n",
    "\n",
    "predict_arr = []\n",
    "for row in y_predict_probability:\n",
    "    row_arr = []\n",
    "    for item in row:\n",
    "#         print(float_to_str(item))\n",
    "        row_arr.append(float_to_str(item,4 ))\n",
    "    predict_arr.append(row_arr)\n",
    "    \n",
    "predict_df = pd.DataFrame({'1_sentence':input_text_df.sentence,\n",
    "                           '2_y_predict':y_predict,\n",
    "                           '3_y_predict_name':y_predict_name,\n",
    "                           '4_y_predict_probability':predict_arr})\n",
    "\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability_list = list(predict_df['4_y_predict_probability'].values)\n",
    "# predict_list = [range(0,len(mapping_list))]\n",
    "# predict_name =[mapping_list]\n",
    "# probability_mapping_df = pd.DataFrame({'predict':predict_list[0],\n",
    "#                                        'predict_name':predict_name[0],\n",
    "#                                        'probability':probability_list[0]})\n",
    "# probability_mapping_df.sort_values(by=['probability'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot_id='robot_a'\n",
    "# data = []\n",
    "# for index, row in predict_df.iterrows():\n",
    "    \n",
    "#     probability_list = row['4_y_predict_probability']\n",
    "# #     print(probability_list) \n",
    "#     predict_list = range(0,len(mapping_list))\n",
    "# #     print(predict_list) \n",
    "#     predict_name =mapping_list\n",
    "# #     print(predict_name) \n",
    "#     probability_mapping_df = pd.DataFrame({'predict':predict_list,\n",
    "#                                            'predict_name':predict_name,\n",
    "#                                            'probability':probability_list})\n",
    "# #     print(probability_mapping_df)\n",
    "#     probability_mapping_df = probability_mapping_df.\\\n",
    "#                             sort_values(by=['probability'], ascending=False).\\\n",
    "#                             reset_index(drop=True)\n",
    "# #     print(probability_mapping_df)\n",
    "    \n",
    "#     predict_result = dict(sentence=row['1_sentence'],\n",
    "#                           predict=list(probability_mapping_df['predict']),\n",
    "#                           predict_skill=list(probability_mapping_df['predict_name']),\n",
    "#                           confidence=list(probability_mapping_df['probability']))\n",
    "    \n",
    "#     result = dict(robot_id=robot_id,\n",
    "#                   skill=mapping_list,\n",
    "#                   predict=predict_result)\n",
    "#     data.append(result)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leave</td>\n",
       "      <td>不來公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leave</td>\n",
       "      <td>不能來公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leave</td>\n",
       "      <td>不進公司了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave</td>\n",
       "      <td>事假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leave</td>\n",
       "      <td>休假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leave</td>\n",
       "      <td>公出</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leave</td>\n",
       "      <td>出勤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>leave</td>\n",
       "      <td>出差</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>leave</td>\n",
       "      <td>填個特休假單</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>leave</td>\n",
       "      <td>填假單</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>leave</td>\n",
       "      <td>寫假單</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>leave</td>\n",
       "      <td>旅行請特休</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>leave</td>\n",
       "      <td>有事無法去公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>leave</td>\n",
       "      <td>有事請事假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>leave</td>\n",
       "      <td>有事請假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>leave</td>\n",
       "      <td>特休假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>leave</td>\n",
       "      <td>生病了不能去公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>leave</td>\n",
       "      <td>生病了幫我請假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>leave</td>\n",
       "      <td>申請休假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>leave</td>\n",
       "      <td>病假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>leave</td>\n",
       "      <td>處理出勤異常</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>leave</td>\n",
       "      <td>補假單</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>leave</td>\n",
       "      <td>要先走接小孩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>leave</td>\n",
       "      <td>要去看醫生</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>leave</td>\n",
       "      <td>要請2小時特休</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>leave</td>\n",
       "      <td>請個假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>leave</td>\n",
       "      <td>請假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>leave</td>\n",
       "      <td>請假半天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>leave</td>\n",
       "      <td>請假單</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>leave</td>\n",
       "      <td>請公出假</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>weather</td>\n",
       "      <td>下雪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>weather</td>\n",
       "      <td>大太陽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣冷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣如何</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣很熱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣狀況</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣資訊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>weather</td>\n",
       "      <td>天氣預報</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>weather</td>\n",
       "      <td>太陽很大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>weather</td>\n",
       "      <td>帶傘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>weather</td>\n",
       "      <td>帶外套</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>weather</td>\n",
       "      <td>擦防曬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>weather</td>\n",
       "      <td>放晴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>weather</td>\n",
       "      <td>旅遊天氣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>weather</td>\n",
       "      <td>會很熱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>weather</td>\n",
       "      <td>氣溫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>weather</td>\n",
       "      <td>氣溫幾度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>weather</td>\n",
       "      <td>氣象</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>weather</td>\n",
       "      <td>溫度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>weather</td>\n",
       "      <td>溼度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>weather</td>\n",
       "      <td>濕度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>weather</td>\n",
       "      <td>穿外套</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>weather</td>\n",
       "      <td>豪大雨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>weather</td>\n",
       "      <td>降雨機率</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>weather</td>\n",
       "      <td>雨傘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>weather</td>\n",
       "      <td>雨衣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>weather</td>\n",
       "      <td>風大不大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>weather</td>\n",
       "      <td>颱風</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>weather</td>\n",
       "      <td>高溫幾度</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   skill_id  sentence\n",
       "0     leave      不來公司\n",
       "1     leave     不能來公司\n",
       "2     leave     不進公司了\n",
       "3     leave        事假\n",
       "4     leave        休假\n",
       "5     leave        公出\n",
       "6     leave        出勤\n",
       "7     leave        出差\n",
       "8     leave    填個特休假單\n",
       "9     leave       填假單\n",
       "10    leave       寫假單\n",
       "11    leave     旅行請特休\n",
       "12    leave   有事無法去公司\n",
       "13    leave     有事請事假\n",
       "14    leave      有事請假\n",
       "15    leave       特休假\n",
       "16    leave  生病了不能去公司\n",
       "17    leave   生病了幫我請假\n",
       "18    leave      申請休假\n",
       "19    leave        病假\n",
       "20    leave    處理出勤異常\n",
       "21    leave       補假單\n",
       "22    leave    要先走接小孩\n",
       "23    leave     要去看醫生\n",
       "24    leave   要請2小時特休\n",
       "25    leave       請個假\n",
       "26    leave        請假\n",
       "27    leave      請假半天\n",
       "28    leave       請假單\n",
       "29    leave      請公出假\n",
       "..      ...       ...\n",
       "61  weather        下雪\n",
       "62  weather       大太陽\n",
       "63  weather        天氣\n",
       "64  weather       天氣冷\n",
       "65  weather      天氣如何\n",
       "66  weather      天氣很熱\n",
       "67  weather      天氣狀況\n",
       "68  weather      天氣資訊\n",
       "69  weather      天氣預報\n",
       "70  weather      太陽很大\n",
       "71  weather        帶傘\n",
       "72  weather       帶外套\n",
       "73  weather       擦防曬\n",
       "74  weather        放晴\n",
       "75  weather      旅遊天氣\n",
       "76  weather       會很熱\n",
       "77  weather        氣溫\n",
       "78  weather      氣溫幾度\n",
       "79  weather        氣象\n",
       "80  weather        溫度\n",
       "81  weather        溼度\n",
       "82  weather        濕度\n",
       "83  weather       穿外套\n",
       "84  weather       豪大雨\n",
       "85  weather      降雨機率\n",
       "86  weather        雨傘\n",
       "87  weather        雨衣\n",
       "88  weather      風大不大\n",
       "89  weather        颱風\n",
       "90  weather      高溫幾度\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_id = 'hr.00001318'\n",
    "min_confidence = 0.9\n",
    "\n",
    "HELPER_KEYSPACE = 'helper_keyspace'\n",
    "HELPER_INTENT_MODEL_DATA_TABLE = 'intent_model_data'\n",
    "HELPER_INTENT_TRAINING_DATA_TABLE = 'intent_training_data'\n",
    "\n",
    "\"\"\"\n",
    "與訓練句子比對\n",
    "\"\"\"\n",
    "cql = (\"select skill_id,sentence from \" + HELPER_INTENT_TRAINING_DATA_TABLE +\n",
    "               \" where robot_id = '\" + robot_id + \"';\")\n",
    "pd_df = c_dao.execCQLSelectToPandasDF(HELPER_KEYSPACE, cql)\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'leave', u'phone', u'weather']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cql = (\"select * from \" + HELPER_INTENT_MODEL_DATA_TABLE + \" where robot_id = '\" + robot_id + \"';\")\n",
    "mapping_df = c_dao.execCQLSelectToPandasDF(HELPER_KEYSPACE, cql)\n",
    "if len(mapping_df):\n",
    "    mapping_list = list(mapping_df['mapping'][0])\n",
    "    \n",
    "mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapping_skill_list</th>\n",
       "      <th>probability</th>\n",
       "      <th>sentence</th>\n",
       "      <th>skill_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[None, phone, weather]</td>\n",
       "      <td>[0, 0.5, 0.5]</td>\n",
       "      <td>打個MVPN給陳俊宏天氣</td>\n",
       "      <td>[phone, weather]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mapping_skill_list    probability      sentence        skill_list\n",
       "0  [None, phone, weather]  [0, 0.5, 0.5]  打個MVPN給陳俊宏天氣  [phone, weather]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = []\n",
    "skill_list = []\n",
    "mapping_skill_list = []\n",
    "probability_list = []\n",
    "for ii, sentence in enumerate(['打個MVPN給陳俊宏天氣']):\n",
    "    \n",
    "    # 新句子比對訓練句子找出相關的skill\n",
    "    skill_list_temp = []\n",
    "    for i, row in pd_df.iterrows():\n",
    "        if row['sentence'].lower().encode('utf8') in sentence.lower():\n",
    "            skill_list_temp.append(row['skill_id'])\n",
    "    # remove duplicate & 限制最多意圖數\n",
    "    skill_list_temp = list(set(skill_list_temp))\n",
    "    skill_list.append(skill_list_temp)\n",
    "    # 補上none方便識別\n",
    "    mapping_skill_list.append([None] * len(mapping_list))\n",
    "    if len(skill_list) > 0:\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    for i, value in enumerate(skill_list_temp):\n",
    "        mapping_skill_list[ii][mapping_list.index(value)] = value         \n",
    "    \n",
    "    # 計算機率\n",
    "    if len(skill_list[ii]) > 0:\n",
    "        probability = float(1)/len(skill_list[ii])\n",
    "    else:\n",
    "        probability = 0\n",
    "    # none的話就把機率補 0\n",
    "    probability_list_temp = []\n",
    "    for x in mapping_skill_list[ii]:\n",
    "        if x:\n",
    "            probability_list_temp.append(probability)\n",
    "        else:\n",
    "            probability_list_temp.append(0)\n",
    "    probability_list.append(probability_list_temp)\n",
    "\n",
    "keyword_predict_df = pd.DataFrame({'skill_list': skill_list,\n",
    "                                  'mapping_skill_list': mapping_skill_list,\n",
    "                                  'sentence': sentence_list,\n",
    "                                  'probability':probability_list})\n",
    "keyword_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predict': {'confidence': [0.5, 0.5, 0.0],\n",
       "   'min_confidence': 0.9,\n",
       "   'predict': [1, 2, 0],\n",
       "   'predict_skill': [u'phone', u'weather', u'leave'],\n",
       "   'sentence': '\\xe6\\x89\\x93\\xe5\\x80\\x8bMVPN\\xe7\\xb5\\xa6\\xe9\\x99\\xb3\\xe4\\xbf\\x8a\\xe5\\xae\\x8f\\xe5\\xa4\\xa9\\xe6\\xb0\\xa3'},\n",
       "  'robot_id': 'hr.00001318'}]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in keyword_predict_df.iterrows():\n",
    "\n",
    "    data = []\n",
    "    if len(row['skill_list']) > 0:\n",
    "\n",
    "        def count_probability(skill_list, mapping_skill_list):\n",
    "            probability = float(1) / len(skill_list)\n",
    "            probability_list = []\n",
    "            for x in mapping_skill_list:\n",
    "                if x:\n",
    "                    probability_list.append(probability)\n",
    "                else:\n",
    "                    probability_list.append(0)\n",
    "\n",
    "            return probability_list\n",
    "\n",
    "        # predict_df['probability'] = predict_df.apply(count_probability, axis=1)\n",
    "\n",
    "        probability_list = count_probability(row['skill_list'], row['mapping_skill_list'])\n",
    "        #     print(probability_list)\n",
    "        predict_list = range(0, len(mapping_list))\n",
    "        #     print(predict_list)\n",
    "        predict_name = mapping_list\n",
    "        #     print(predict_name)\n",
    "        probability_mapping_df = pd.DataFrame({'predict': predict_list,\n",
    "                                               'predict_name': predict_name,\n",
    "                                               'probability': probability_list})\n",
    "        #     print(probability_mapping_df)\n",
    "        probability_mapping_df = probability_mapping_df. \\\n",
    "            sort_values(by=['probability'], ascending=False). \\\n",
    "            reset_index(drop=True)\n",
    "        #     print(probability_mapping_df)\n",
    "\n",
    "        predict_result = dict(sentence=row['sentence'],\n",
    "                              predict=list(probability_mapping_df['predict']),\n",
    "                              predict_skill=list(probability_mapping_df['predict_name']),\n",
    "                              confidence=list(probability_mapping_df['probability']),\n",
    "                              min_confidence=min_confidence)\n",
    "\n",
    "        result = dict(robot_id=robot_id,\n",
    "                      predict=predict_result)\n",
    "        # result = dict(robot_id=robot_id,\n",
    "        #               skill=mapping_list,\n",
    "        #               predict=predict_result)\n",
    "        data.append(result)\n",
    "    else:\n",
    "        print 'model predict ~~~~~~~~~'\n",
    "        \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predict': {'confidence': [0.3333333333333333,\n",
       "    0.3333333333333333,\n",
       "    0.3333333333333333],\n",
       "   'min_confidence': 0.9,\n",
       "   'predict': [0, 1, 2],\n",
       "   'predict_skill': [u'leave', u'phone', u'weather'],\n",
       "   'sentence': '\\xe6\\x89\\x93\\xe5\\x80\\x8bMVPN\\xe7\\xb5\\xa6\\xe9\\x99\\xb3\\xe4\\xbf\\x8a\\xe5\\xae\\x8f\\xe5\\xa4\\xa9\\xe6\\xb0\\xa3\\xe6\\xba\\xab\\xe5\\xba\\xa6'},\n",
       "  'robot_id': 'hr.00001318'}]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = []\n",
    "# if len(predict_df) > 0:\n",
    "    \n",
    "#     def count_probability(row):\n",
    "#         probability = float(1) / len(row['skill_list'])\n",
    "#         probability_list = []\n",
    "#         for x in row['mapping_skill_list']:\n",
    "#             if x:\n",
    "#                 probability_list.append(probability)\n",
    "#             else:\n",
    "#                 probability_list.append(0)\n",
    "\n",
    "#         return probability_list\n",
    "\n",
    "#     predict_df['probability'] = predict_df.apply(count_probability, axis=1)\n",
    "\n",
    "#     for index, row in predict_df.iterrows():\n",
    "\n",
    "#         # print(predict_df)\n",
    "\n",
    "#         probability_list = row['probability']\n",
    "#         #     print(probability_list)\n",
    "#         predict_list = range(0, len(mapping_list))\n",
    "#         #     print(predict_list)\n",
    "#         predict_name = mapping_list\n",
    "#         #     print(predict_name)\n",
    "#         probability_mapping_df = pd.DataFrame({'predict': predict_list,\n",
    "#                                                'predict_name': predict_name,\n",
    "#                                                'probability': probability_list})\n",
    "#         #     print(probability_mapping_df)\n",
    "#         probability_mapping_df = probability_mapping_df. \\\n",
    "#             sort_values(by=['probability'], ascending=False). \\\n",
    "#             reset_index(drop=True)\n",
    "#         #     print(probability_mapping_df)\n",
    "\n",
    "#         predict_result = dict(sentence=row['sentence'],\n",
    "#                               predict=list(probability_mapping_df['predict']),\n",
    "#                               predict_skill=list(probability_mapping_df['predict_name']),\n",
    "#                               confidence=list(probability_mapping_df['probability']),\n",
    "#                               min_confidence=min_confidence)\n",
    "\n",
    "#         result = dict(robot_id=robot_id,\n",
    "#                       predict=predict_result)\n",
    "#         # result = dict(robot_id=robot_id,\n",
    "#         #               skill=mapping_list,\n",
    "#         #               predict=predict_result)\n",
    "#         data.append(result)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
